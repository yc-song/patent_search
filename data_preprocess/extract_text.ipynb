{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "# from langchain.llms import HuggingFaceHub\n",
    "\n",
    "from textutils import extract_ref_from_text, get_number2drawing_dict, convert_ref_to_drawing_num\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "os.chdir('/Users/hayley/Documents/p4ds/patent_search')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import textutils\n",
    "importlib.reload(textutils)\n",
    "from textutils import extract_ref_from_text, get_number2drawing_dict, convert_refs_to_drawing_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py 돌려서 나온 결과 다시 저장\n",
    "# sample_data = pd.read_csv('data_preprocess/data.csv')\n",
    "# sample_data.to_excel(\"data_preprocess/data.xlsx\")\n",
    "\n",
    "# 근데 코드에서 코너 케이스 때문에 처리가 안된 pdf 가 있어서 그거는 excel 파일 다운받아서 눈으로 보고 채움 -> 그러다보니까 \\n이 안지워진 경우가 있어서 지웠음\n",
    "# sample_data = pd.read_excel('data_preprocess/data.xlsx')\n",
    "# for col in sample_data.columns:\n",
    "#     sample_data[col] = sample_data[col].str.replace('\\n', '')\n",
    "# sample_data.to_excel(\"data_preprocess/data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # negative sample 3개 추가하느라고 다시 main.py 돌리고 안읽어와진 ~605번 특허 처리\n",
    "# sample_data = pd.read_csv('data_preprocess/data.csv')\n",
    "\n",
    "# sample_data_orig = pd.read_excel(\"data_preprocess/sample_data.xlsx\", index_col=0)\n",
    "# sample_data_orig.to_excel(\"data_preprocess/sample_data_old.xlsx\") # save old version as _old\n",
    "\n",
    "# sample_data.loc[len(sample_data)-1, :] = sample_data_orig.loc[3, :]\n",
    "# sample_data['id'] = sample_data['id'].astype(float).astype(int).astype(str)\n",
    "# # add labels column\n",
    "# sample_data['labels'] = \"\"\n",
    "# sample_data.loc[sample_data['id']=='1020180014052', 'labels'] = 'source'\n",
    "# sample_data.loc[sample_data['id'].isin(['1020050097605','1020177009557', '1020120156759']), 'labels'] = 'target'\n",
    "# sample_data.loc[sample_data['id'].isin(['1020127022798','1020157015204', '1020200149050']), 'labels'] = 'negative'\n",
    "# sample_data.to_excel(\"data_preprocess/sample_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "## negative sample data 를 더 추가해볼까?\n",
    "sample_data = pd.read_excel(\"data_preprocess/sample_data_old.xlsx\", index_col=0)\n",
    "negative_samples = pd.read_csv('pdf_process/data.csv')\n",
    "negative_samples['id'] = negative_samples['id'].astype(str)\n",
    "\n",
    "# for i, row in negative_samples.iterrows():\n",
    "#     try:\n",
    "#         tmp_id = int(row['id'])\n",
    "#     except:\n",
    "#         print(i, row['id'])\n",
    "        \n",
    "negative_samples = negative_samples.loc[negative_samples['id']!= '1020160014413 (1)']\n",
    "\n",
    "# for i, row in negative_samples.iterrows():\n",
    "#     try:\n",
    "#         tmp_id = int(row['id'])\n",
    "#     except:\n",
    "#         print(i, row['id'])\n",
    "        \n",
    "negative_samples = negative_samples.loc[~negative_samples['id'].isin(sample_data['id'])]\n",
    "sample_data = pd.concat([sample_data, negative_samples], axis=0)\n",
    "\n",
    "# add labels column\n",
    "sample_data['labels'] = \"\"\n",
    "sample_data.loc[sample_data['id']=='1020180014052', 'labels'] = 'source'\n",
    "sample_data.loc[sample_data['id'].isin(['1020050097605','1020177009557', '1020120156759']), 'labels'] = 'target'\n",
    "sample_data['labels'] = sample_data['labels'].fillna(\"negative\")\n",
    "sample_data.to_excel(\"data_preprocess/sample_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: text only embedding search\n",
    "\n",
    "- Result: using 3 golden targets and 96 negative samples and 1 source, within top 4 retrieved chunks, all of them are from golden related patents.\n",
    "- source: 1020180014052 (10-1990984 patent)\n",
    "- target: \n",
    "    - KR1020070041937 A* (1020050097605 app)\n",
    "    - KR1020170071490 A* (10-2017-7009557 app)\n",
    "    - KR101414532 B1 (10-2012-0156759 app)\n",
    "- negative:\n",
    "    - all others from 100 crawled patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TokenTextSplitter -> split by number of tokens. use tokenizer from OpenAI\n",
    "# https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "# cl100k_base is the tokenizer for the latest embedding (v2)\n",
    "text_splitter = TokenTextSplitter.from_tiktoken_encoder(\"cl100k_base\",\n",
    "                                                        chunk_size=500, \n",
    "                                                        chunk_overlap=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_chunk_dicts=[]\n",
    "text_columns = ['요약', '청구범위', '기술분야', '배경기술', '해결하려는과제', '과제의해결수단',\n",
    "       '발명의효과', '도면의간단한설명', '발명을실시하기위한구체적인내용', '부호의설명']\n",
    "\n",
    "for i, row in sample_data.iterrows():\n",
    "    patent_dict = dict( \n",
    "        # 특허 번호 따기\n",
    "        application_number = str(row.id), # 출원 번호\n",
    "        publication_number = '', # 공개 번호\n",
    "        patent_number = '', # 등록 번호\n",
    "        chunks = [],\n",
    "    )\n",
    "    print(f\"patent {row.id} 's chunk sizes\")\n",
    "    \n",
    "    # text column들을 돌면서, chunking 하기\n",
    "    chunks = []\n",
    "    drawing_nums_list = []\n",
    "    refs_list = []\n",
    "    for col in text_columns:\n",
    "        if (col in ['도면의간단한설명', '부호의설명']) or (str(row[col]) == 'nan'): # 도면의 간단한 설명, 부호의 설명은 embed 하지 않음!\n",
    "            continue\n",
    "        curr_section_chunks = text_splitter.create_documents([str(row[col])], [{\"application_number\": str(row.id)}])\n",
    "        chunks.extend(curr_section_chunks)\n",
    "        \n",
    "        print(col, len(curr_section_chunks), end=' | ')\n",
    "        \n",
    "        # # chunk 별로 reference 발생한 부호 찾기\n",
    "        # for chnk in curr_section_chunks:\n",
    "        #     refs = extract_ref_from_text(chnk)\n",
    "        #     refs_list.append(refs)\n",
    "            \n",
    "        #     #  부호가 있었으면 drawing number 로 한번 또 치환하기\n",
    "        #     if len(refs) > 0: # if not empty, convert found references to drawing numbers\n",
    "        #         drawing_nums = convert_refs_to_drawing_num(refs, num2drawing_dicts[str(row.id)]['num2drawing'])\n",
    "        #     else:\n",
    "        #         drawing_nums = []\n",
    "        #     drawing_nums_list.append(drawing_nums)\n",
    "                \n",
    "        \n",
    "    # patent_dict['chunks'] = list(zip(chunks, zip(refs_list, drawing_nums_list)))\n",
    "    patent_dict['chunks'] = chunks\n",
    "    print()\n",
    "    patent_chunk_dicts.append(patent_dict)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(patent_chunk_dicts, open('data_preprocess/sample_chunk_data.json', 'w'), ensure_ascii = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 7166/7166 [42:46<00:00,  2.79it/s]  \n"
     ]
    }
   ],
   "source": [
    "all_chunks = [x['chunks'] for x in patent_chunk_dicts if x['application_number'] != '1020180014052']\n",
    "all_chunks = sum(all_chunks, [])\n",
    "# print(len(all_chunks))\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents([all_chunks[0]], embedding=embeddings)\n",
    "for chunk in tqdm(all_chunks[1:]):  # used for loop since if input all chunks at once, RATE LIMIT error occurred.\n",
    "    vectorstore.add_documents([chunk])\n",
    "    # time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한 플렉서블 열전 모듈을 구비한 의류에서 플렉서블 열전 모듈 및 제어부가 사시도로 도시되어 있으며, 도 5에는 본 발명에 의한 플렉서블 열전 모듈을 구비한 의류에서 플렉서블 열전 모듈이 측면도로 도시되어 있다.이들 도면에 의하면, 본 발명의 플렉서블 열전 모듈을 구비한 의류는 의류(100), 플렉서블 열전 모듈(200) 및제어부(300)를 포함한다.의류(100)는 사용자가 착용할 수 있도록 하는 상의 또는 하의를 포함하며, 후술할 플렉서블 열전 모듈(200)이선택적인 위치에 탈부착 될 수 있도록 내피에 수용부가 구비된다. 이때, 상기 의류(100)는 상의인 것으로 예시하며, 하의나 신체의 일부에 착용할 수 있는 형태로도 대체할 수 있다.플렉서블  열전  모듈(200)은  의류(100)의  내피에  장착되어  전원이 인가되면 펠티어(Peltier)  효과에 따라 일측접합부에서 열을 흡수하고 타측 접합부에서 열을 발산한다. 여기서, 열전 모듈은 열에너지와 전기에너지의 상호변환이 가능한 친환경적인 에너지재료로써, 알루미나 등의 세라\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\n",
    "    \"냉각  제어  모듈,  이를  포함하는  손목  냉각  밴드  및  웨어러블  냉각  장치가  개시된다.  \\\n",
    "    본  발명의  일  측면에따르면, 신체에 냉감을 일으키는 냉각 제어 모듈로서, 흡열표면과 발열표면을 가지는 열전소자와; \\\n",
    "    상기 열전소자에 전원을 공급하기 위한 전원 공급부와; 상기 열전소자의 발열표면에 부착되어 열을 발산하는 방열부재(放熱部材)를  포함하며,\\\n",
    "    상기  방열부재는,  일정  두께를  갖고  두께  방향으로  상기  열을  이동시키는  열분해  흑연  패드(pyrolytic graphite pad)와 \\\n",
    "    금속 방열판이 교대로 적층되어 형성되는, 냉각 제어 모듈이 제공된다.\"\n",
    ")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='한 플렉서블 열전 모듈을 구비한 의류에서 플렉서블 열전 모듈 및 제어부가 사시도로 도시되어 있으며, 도 5에는 본 발명에 의한 플렉서블 열전 모듈을 구비한 의류에서 플렉서블 열전 모듈이 측면도로 도시되어 있다.이들 도면에 의하면, 본 발명의 플렉서블 열전 모듈을 구비한 의류는 의류(100), 플렉서블 열전 모듈(200) 및제어부(300)를 포함한다.의류(100)는 사용자가 착용할 수 있도록 하는 상의 또는 하의를 포함하며, 후술할 플렉서블 열전 모듈(200)이선택적인 위치에 탈부착 될 수 있도록 내피에 수용부가 구비된다. 이때, 상기 의류(100)는 상의인 것으로 예시하며, 하의나 신체의 일부에 착용할 수 있는 형태로도 대체할 수 있다.플렉서블  열전  모듈(200)은  의류(100)의  내피에  장착되어  전원이 인가되면 펠티어(Peltier)  효과에 따라 일측접합부에서 열을 흡수하고 타측 접합부에서 열을 발산한다. 여기서, 열전 모듈은 열에너지와 전기에너지의 상호변환이 가능한 친환경적인 에너지재료로써, 알루미나 등의 세라', metadata={'application_number': '1020120156759'}),\n",
       " Document(page_content='본 발명은 열전소자를 이용한 백라이트 유닛의 냉각 시스템 및 냉각 방법에 관한 것으로서, 특히 백라이트유닛으로부터 전달된 열을 열전소자에 의해 냉각시키고 발열함으로써 방열팬, 방열핀등의 추가적인 구성이없이 간단히 백라이트 유닛을 냉각할 수 있다는 이점이 있다.이를 위하여 본 발명은 백라이트 유닛과 연결되어 상기 백라이트 유닛에서 발생하는 열을 냉각하는 열전소자를 이용하는 백라이트 유닛의 냉각 시스템에 있어서, 상기 백라이트 유닛의 열원으로부터 열을 흡수하여열전소자에 열을 전달하는 내부 열흡수부; 그 일면은 상기 내부 열흡수부로부터 열을 흡수하여 냉각하고,다른 면은 흡수한 열을 방출하는 열전소자; 및 상기 열전소자로부터 방출된 열을 흡수하여 외부로 방출하는 외부 발열부를 포함한다.', metadata={'application_number': '1020050097605'}),\n",
       " Document(page_content='본 발명은 플렉서블 열전 모듈을 구비한 의류에 관한 것으로, 본 발명은, 신체에 착용 가능한 의류; 상기 의류의내부에 탈부착되되, 상하 배치되어 대향되는 접합면에 절연층이 각각 구비되는 제1, 2 기판과, 상기 절연층 상에각각 구비되는 제1, 2 전극 패턴 및 상기 제1, 2 전극 패턴의 사이에 박막 또는 후막 형태로 개입되며, 양면에상기 제1, 2 전극이 교호되게 접합되는 P형 및 N형 열전 물질층을 포함하는 플렉서블 열전 모듈; 및 상기 의류중 특정 부위에 착용하며, 상기 플렉서블 열전 모듈과 전기적으로 연결되어 상기 플렉서블 열전 모듈에 전원 공급 및 작동 상태를 제어하는 제어부를 포함한다.본 발명에 의하면, 펠티어(Peltier) 효과에 따라 일측에서 열을 흡수하고 타측에서 열을 발산하는 열전 모듈을유연성을 갖도록 하면서 의류 내에 장착하여 하나의 모듈로 냉각 또는 발열 의류를 모두 구현할 수 있는 효과가있다.', metadata={'application_number': '1020120156759'}),\n",
       " Document(page_content='본 발명의 목적은 상기한 바와 같은 종래 기술의 문제점을 해결하기 위한 것으로, 펠티어(Peltier) 효과에 따라일측에서 열을 흡수하고 타측에서 열을 발산하는 열전 모듈을 유연성을 갖도록 하면서 의류 내에 장착하여 하나의 모듈로 냉각 또는 발열 의류를 모두 구현할 수 있게 한 플렉서블 열전 모듈을 구비한 의류를 제공하는 것이다.', metadata={'application_number': '1020120156759'})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또다른 방법 \n",
    "query = \"냉각  제어  모듈,  이를  포함하는  손목  냉각  밴드  및  웨어러블  냉각  장치가  개시된다.  \\\n",
    "    본  발명의  일  측면에따르면, 신체에 냉감을 일으키는 냉각 제어 모듈로서, 흡열표면과 발열표면을 가지는 열전소자와; \\\n",
    "    상기 열전소자에 전원을 공급하기 위한 전원 공급부와; 상기 열전소자의 발열표면에 부착되어 열을 발산하는 방열부재(放熱部材)를  포함하며,\\\n",
    "    상기  방열부재는,  일정  두께를  갖고  두께  방향으로  상기  열을  이동시키는  열분해  흑연  패드(pyrolytic graphite pad)와 \\\n",
    "    금속 방열판이 교대로 적층되어 형성되는, 냉각 제어 모듈이 제공된다.\"\n",
    "docs = vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='한 플렉서블 열전 모듈을 구비한 의류에서 플렉서블 열전 모듈 및 제어부가 사시도로 도시되어 있으며, 도 5에는 본 발명에 의한 플렉서블 열전 모듈을 구비한 의류에서 플렉서블 열전 모듈이 측면도로 도시되어 있다.이들 도면에 의하면, 본 발명의 플렉서블 열전 모듈을 구비한 의류는 의류(100), 플렉서블 열전 모듈(200) 및제어부(300)를 포함한다.의류(100)는 사용자가 착용할 수 있도록 하는 상의 또는 하의를 포함하며, 후술할 플렉서블 열전 모듈(200)이선택적인 위치에 탈부착 될 수 있도록 내피에 수용부가 구비된다. 이때, 상기 의류(100)는 상의인 것으로 예시하며, 하의나 신체의 일부에 착용할 수 있는 형태로도 대체할 수 있다.플렉서블  열전  모듈(200)은  의류(100)의  내피에  장착되어  전원이 인가되면 펠티어(Peltier)  효과에 따라 일측접합부에서 열을 흡수하고 타측 접합부에서 열을 발산한다. 여기서, 열전 모듈은 열에너지와 전기에너지의 상호변환이 가능한 친환경적인 에너지재료로써, 알루미나 등의 세라', metadata={'application_number': '1020120156759'}),\n",
       " Document(page_content='본 발명은 열전소자를 이용한 백라이트 유닛의 냉각 시스템 및 냉각 방법에 관한 것으로서, 특히 백라이트유닛으로부터 전달된 열을 열전소자에 의해 냉각시키고 발열함으로써 방열팬, 방열핀등의 추가적인 구성이없이 간단히 백라이트 유닛을 냉각할 수 있다는 이점이 있다.이를 위하여 본 발명은 백라이트 유닛과 연결되어 상기 백라이트 유닛에서 발생하는 열을 냉각하는 열전소자를 이용하는 백라이트 유닛의 냉각 시스템에 있어서, 상기 백라이트 유닛의 열원으로부터 열을 흡수하여열전소자에 열을 전달하는 내부 열흡수부; 그 일면은 상기 내부 열흡수부로부터 열을 흡수하여 냉각하고,다른 면은 흡수한 열을 방출하는 열전소자; 및 상기 열전소자로부터 방출된 열을 흡수하여 외부로 방출하는 외부 발열부를 포함한다.', metadata={'application_number': '1020050097605'}),\n",
       " Document(page_content='본 발명은 플렉서블 열전 모듈을 구비한 의류에 관한 것으로, 본 발명은, 신체에 착용 가능한 의류; 상기 의류의내부에 탈부착되되, 상하 배치되어 대향되는 접합면에 절연층이 각각 구비되는 제1, 2 기판과, 상기 절연층 상에각각 구비되는 제1, 2 전극 패턴 및 상기 제1, 2 전극 패턴의 사이에 박막 또는 후막 형태로 개입되며, 양면에상기 제1, 2 전극이 교호되게 접합되는 P형 및 N형 열전 물질층을 포함하는 플렉서블 열전 모듈; 및 상기 의류중 특정 부위에 착용하며, 상기 플렉서블 열전 모듈과 전기적으로 연결되어 상기 플렉서블 열전 모듈에 전원 공급 및 작동 상태를 제어하는 제어부를 포함한다.본 발명에 의하면, 펠티어(Peltier) 효과에 따라 일측에서 열을 흡수하고 타측에서 열을 발산하는 열전 모듈을유연성을 갖도록 하면서 의류 내에 장착하여 하나의 모듈로 냉각 또는 발열 의류를 모두 구현할 수 있는 효과가있다.', metadata={'application_number': '1020120156759'}),\n",
       " Document(page_content='본 발명의 목적은 상기한 바와 같은 종래 기술의 문제점을 해결하기 위한 것으로, 펠티어(Peltier) 효과에 따라일측에서 열을 흡수하고 타측에서 열을 발산하는 열전 모듈을 유연성을 갖도록 하면서 의류 내에 장착하여 하나의 모듈로 냉각 또는 발열 의류를 모두 구현할 수 있게 한 플렉서블 열전 모듈을 구비한 의류를 제공하는 것이다.', metadata={'application_number': '1020120156759'})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "**logs**\n",
    "\n",
    "23.11.15\n",
    "\n",
    "- 1) problem with extracting reference (number) from texts -> some reference codes are not just numbers. it's number + alphabet e.g. 202a, 202b, or sometimes just uppercase alphabets e.g. T, SR~SZ\n",
    "- 2) so I tried to first extract the reference codes from \"부호에 대한 설명\" column. (Because then I can find those specific reference codes inside of texts.) But extracting reference codes from \"부호에 대한 설명\" was difficult because currently all \\<code\\>: \\<description\\> string pairs are concatenated without \\n and the parsing reference codes by just relying on regular expression was almost impossible. (some reference codes were uppercase alphabets, but including uppercase alphabets for codes caused problems.) So I asked Mooho if he could leave \\n characters left for \"부호에 대한 설명\" section. He said yes, and I paused developing regex rules further.  \n",
    "\n",
    "23.11.16\n",
    "- I proceeded with some noise in reference extraction. \n",
    "- I also added some negative samples (3 random samples that are not prior arts of the source patent.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_excel('data_preprocess/sample_data.xlsx',index_col=0)\n",
    "\n",
    "## image to numbers, numbers to image\n",
    "num2drawing_dicts = get_number2drawing_dict('/Users/hayley/Documents/p4ds/patent_search/data_preprocess/mock_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.f. hupd에서 쓴 컬럼들 \n",
    "#     \"abstract\": \"...\", # 요약 -> 우리나라 특허에는 abstract가 따로 있는거 같진 않고 요약 1개 섹션임\n",
    "#     \"claims\": \"...\", # 청구범위\n",
    "#     \"background\": \"...\", # 기술분야 + 배경기술\n",
    "#     \"summary\": \"...\", # 요약? \n",
    "#     \"full_description\": \"...\" # 해결하려는과제 + 과제의해결수단 + 발명의효과 + 발명을실시하기위한구체적인내용???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', '요약', '대표도', '청구범위', '기술분야', '배경기술', '해결하려는과제', '과제의해결수단',\n",
       "       '발명의효과', '도면의간단한설명', '발명을실시하기위한구체적인내용', '부호의설명'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.columns \n",
    "# text embedding 대상이 되는 컬럼\n",
    "# '요약', '청구범위', '기술분야', '배경기술', '해결하려는과제', '과제의해결수단',\n",
    "#        '발명의효과', '도면의간단한설명', '발명을실시하기위한구체적인내용', '부호의설명'\n",
    "\n",
    "# 각 섹션을 따로 따로 임베딩하는게 나을지 아니면은, 몇 섹션은 합치는게 나을지 고민이다. -> 일단 빠르게 ㄱㄱ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = ['요약', '청구범위', '기술분야', '배경기술', '해결하려는과제', '과제의해결수단',\n",
    "       '발명의효과', '도면의간단한설명', '발명을실시하기위한구체적인내용', '부호의설명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # c.f. 컬럼별 길이 분포 \n",
    "# all_data = pd.read_excel('/Users/hayley/Documents/p4ds/patent_search/pdf_process/data_large.xlsx', index_col=0)\n",
    "# for col in all_data.columns:\n",
    "#     try:\n",
    "#         if \"extracted_numbers\" not in col:\n",
    "#             lens = all_data[col].apply(lambda x: len(str(x)))\n",
    "#             print(col, lens.mean().round(2))\n",
    "#     except:\n",
    "#         continue\n",
    "# # id 13.04\n",
    "# # 요약 301.69\n",
    "# # 대표도 395.03\n",
    "# # 청구범위 3565.65\n",
    "# # 기술분야 150.39\n",
    "# # 배경기술 1713.51\n",
    "# # 해결하려는과제 210.42\n",
    "# # 과제의해결수단 1653.4\n",
    "# # 발명의효과 209.81\n",
    "# # 도면의간단한설명 1206.95\n",
    "# # 발명을실시하기위한구체적인내용 17958.91\n",
    "# # 부호의설명 188.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patent 1020157015204 's chunk sizes\n",
      "요약 1 | 청구범위 6 | 기술분야 1 | 배경기술 2 | 발명을실시하기위한구체적인내용 70 | \n",
      "patent 1020120156759 's chunk sizes\n",
      "요약 1 | 기술분야 1 | 배경기술 3 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 14 | \n",
      "patent 1020200149050 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 6 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 8 | \n",
      "patent 1020180014052 's chunk sizes\n",
      "요약 1 | 청구범위 5 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 4 | 발명의효과 1 | 발명을실시하기위한구체적인내용 19 | \n",
      "patent 1020177009557 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 8 | 발명의효과 1 | 발명을실시하기위한구체적인내용 14 | \n",
      "patent 1020127022798 's chunk sizes\n",
      "요약 1 | 청구범위 12 | 기술분야 1 | 배경기술 27 | 발명을실시하기위한구체적인내용 46 | \n",
      "patent 1020050097605 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 배경기술 3 | 해결하려는과제 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 8 | \n",
      "patent 1020080110005 's chunk sizes\n",
      "요약 1 | 기술분야 1 | 배경기술 24 | \n",
      "patent 1020107017567 's chunk sizes\n",
      "요약 1 | 청구범위 8 | 기술분야 1 | 배경기술 3 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 15 | \n",
      "patent 1020110134350 's chunk sizes\n",
      "요약 1 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 2 | 발명의효과 1 | 발명을실시하기위한구체적인내용 7 | \n",
      "patent 1020120022594 's chunk sizes\n",
      "요약 1 | 기술분야 1 | 배경기술 5 | 해결하려는과제 1 | 과제의해결수단 7 | 발명의효과 1 | 발명을실시하기위한구체적인내용 19 | \n",
      "patent 1020130013714 's chunk sizes\n",
      "요약 1 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 4 | \n",
      "patent 1020130107833 's chunk sizes\n",
      "요약 1 | 청구범위 8 | 기술분야 1 | 배경기술 1 | 과제의해결수단 7 | 발명을실시하기위한구체적인내용 27 | \n",
      "patent 1020130122266 's chunk sizes\n",
      "요약 1 | 청구범위 9 | 기술분야 1 | 배경기술 1 | 해결하려는과제 2 | 과제의해결수단 2 | 발명의효과 1 | 발명을실시하기위한구체적인내용 64 | \n",
      "patent 1020130151021 's chunk sizes\n",
      "요약 1 | 청구범위 16 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 5 | 발명을실시하기위한구체적인내용 47 | \n",
      "patent 1020137005748 's chunk sizes\n",
      "요약 1 | 청구범위 7 | 기술분야 2 | 배경기술 5 | 해결하려는과제 1 | 과제의해결수단 7 | 발명의효과 2 | 발명을실시하기위한구체적인내용 32 | \n",
      "patent 1020137011934 's chunk sizes\n",
      "요약 1 | 청구범위 8 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명을실시하기위한구체적인내용 92 | \n",
      "patent 1020140010916 's chunk sizes\n",
      "요약 1 | 청구범위 5 | 기술분야 1 | 배경기술 3 | 해결하려는과제 2 | 과제의해결수단 7 | 발명의효과 1 | 발명을실시하기위한구체적인내용 26 | \n",
      "patent 1020140013682 's chunk sizes\n",
      "요약 1 | 청구범위 2 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 2 | 발명의효과 1 | 발명을실시하기위한구체적인내용 4 | \n",
      "patent 1020140069872 's chunk sizes\n",
      "요약 1 | 청구범위 16 | 기술분야 1 | 배경기술 5 | 해결하려는과제 2 | 과제의해결수단 3 | 발명의효과 2 | 발명을실시하기위한구체적인내용 50 | \n",
      "patent 1020140080374 's chunk sizes\n",
      "요약 2 | 청구범위 1 | 기술분야 1 | 배경기술 5 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 1 | 발명을실시하기위한구체적인내용 6 | \n",
      "patent 1020140112870 's chunk sizes\n",
      "요약 1 | 청구범위 6 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 5 | 발명의효과 1 | 발명을실시하기위한구체적인내용 36 | \n",
      "patent 1020147004289 's chunk sizes\n",
      "요약 1 | 청구범위 2 | 기술분야 2 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 135 | \n",
      "patent 1020147024077 's chunk sizes\n",
      "요약 1 | 청구범위 21 | 기술분야 1 | 배경기술 12 | 해결하려는과제 1 | 과제의해결수단 2 | 발명의효과 3 | 발명을실시하기위한구체적인내용 86 | \n",
      "patent 1020150011145 's chunk sizes\n",
      "요약 1 | 청구범위 5 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 4 | 발명의효과 1 | 발명을실시하기위한구체적인내용 52 | \n",
      "patent 1020150058947 's chunk sizes\n",
      "요약 1 | 청구범위 2 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 2 | 발명의효과 1 | 발명을실시하기위한구체적인내용 13 | \n",
      "patent 1020150075771 's chunk sizes\n",
      "요약 1 | 청구범위 10 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 17 | 발명의효과 1 | 발명을실시하기위한구체적인내용 71 | \n",
      "patent 1020150081723 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 6 | \n",
      "patent 1020150090567 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 52 | \n",
      "patent 1020150094124 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 4 | 발명의효과 1 | 발명을실시하기위한구체적인내용 15 | \n",
      "patent 1020150114402 's chunk sizes\n",
      "요약 1 | 청구범위 1 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 4 | \n",
      "patent 1020150141639 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 7 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 2 | 발명을실시하기위한구체적인내용 23 | \n",
      "patent 1020157014957 's chunk sizes\n",
      "요약 1 | 청구범위 5 | 기술분야 1 | 배경기술 3 | 발명을실시하기위한구체적인내용 83 | \n",
      "patent 1020157022143 's chunk sizes\n",
      "요약 1 | 청구범위 8 | 기술분야 1 | 배경기술 4 | 발명을실시하기위한구체적인내용 147 | \n",
      "patent 1020160003918 's chunk sizes\n",
      "요약 1 | 청구범위 7 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 8 | 발명의효과 1 | 발명을실시하기위한구체적인내용 24 | \n",
      "patent 1020160014413 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 2 | 발명을실시하기위한구체적인내용 12 | \n",
      "patent 1020160014442 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 10 | \n",
      "patent 1020160014730 's chunk sizes\n",
      "요약 1 | 청구범위 2 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 9 | \n",
      "patent 1020160043914 's chunk sizes\n",
      "요약 1 | 청구범위 8 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 7 | 발명의효과 2 | 발명을실시하기위한구체적인내용 34 | \n",
      "patent 1020160059963 's chunk sizes\n",
      "요약 1 | 청구범위 8 | 배경기술 1 | 발명을실시하기위한구체적인내용 85 | \n",
      "patent 1020160064891 's chunk sizes\n",
      "요약 1 | 청구범위 6 | 기술분야 1 | 배경기술 4 | 해결하려는과제 1 | 과제의해결수단 4 | 발명의효과 1 | 발명을실시하기위한구체적인내용 11 | \n",
      "patent 1020160093464 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 39 | \n",
      "patent 1020160103537 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 7 | 해결하려는과제 1 | 과제의해결수단 5 | 발명의효과 2 | 발명을실시하기위한구체적인내용 19 | \n",
      "patent 1020160119204 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 7 | 발명의효과 1 | 발명을실시하기위한구체적인내용 37 | \n",
      "patent 1020160135077 's chunk sizes\n",
      "요약 1 | 청구범위 9 | 기술분야 1 | 배경기술 3 | 해결하려는과제 1 | 과제의해결수단 7 | 발명의효과 1 | 발명을실시하기위한구체적인내용 25 | \n",
      "patent 1020160156362 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 7 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 2 | 발명을실시하기위한구체적인내용 16 | \n",
      "patent 1020167000034 's chunk sizes\n",
      "요약 1 | 청구범위 9 | 기술분야 1 | 배경기술 9 | 발명을실시하기위한구체적인내용 154 | \n",
      "patent 1020167004736 's chunk sizes\n",
      "요약 1 | 청구범위 18 | 배경기술 6 | 발명을실시하기위한구체적인내용 122 | \n",
      "patent 1020167014066 's chunk sizes\n",
      "요약 1 | 청구범위 21 | 기술분야 1 | 배경기술 3 | 발명을실시하기위한구체적인내용 223 | \n",
      "patent 1020167023345 's chunk sizes\n",
      "요약 1 | 청구범위 10 | 배경기술 3 | 발명을실시하기위한구체적인내용 128 | \n",
      "patent 1020167026926 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 3 | 해결하려는과제 2 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 44 | \n",
      "patent 1020170007969 's chunk sizes\n",
      "요약 1 | 청구범위 6 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 2 | 발명을실시하기위한구체적인내용 12 | \n",
      "patent 1020170008303 's chunk sizes\n",
      "요약 1 | 청구범위 5 | 기술분야 1 | 배경기술 3 | 해결하려는과제 1 | 과제의해결수단 4 | 발명의효과 1 | 발명을실시하기위한구체적인내용 19 | \n",
      "patent 1020170021111 's chunk sizes\n",
      "요약 1 | 청구범위 9 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 7 | 발명의효과 2 | 발명을실시하기위한구체적인내용 41 | \n",
      "patent 1020170062870 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 4 | 발명의효과 1 | 발명을실시하기위한구체적인내용 10 | \n",
      "patent 1020170063067 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 4 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 1 | 발명을실시하기위한구체적인내용 31 | \n",
      "patent 1020170079495 's chunk sizes\n",
      "요약 2 | 청구범위 3 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 1 | 발명을실시하기위한구체적인내용 7 | \n",
      "patent 1020170120231 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 22 | \n",
      "patent 1020170126625 's chunk sizes\n",
      "요약 1 | 청구범위 8 | 기술분야 1 | 배경기술 3 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 14 | \n",
      "patent 1020170134182 's chunk sizes\n",
      "요약 1 | 청구범위 5 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 2 | 발명의효과 1 | 발명을실시하기위한구체적인내용 10 | \n",
      "patent 1020170146633 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 3 | 해결하려는과제 1 | 과제의해결수단 2 | 발명의효과 1 | 발명을실시하기위한구체적인내용 37 | \n",
      "patent 1020170168323 's chunk sizes\n",
      "요약 1 | 청구범위 2 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 12 | \n",
      "patent 1020177018396 's chunk sizes\n",
      "요약 1 | 청구범위 7 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 8 | 발명의효과 1 | 발명을실시하기위한구체적인내용 26 | \n",
      "patent 1020177025128 's chunk sizes\n",
      "요약 1 | 청구범위 12 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 14 | 발명을실시하기위한구체적인내용 160 | \n",
      "patent 1020177026522 's chunk sizes\n",
      "요약 1 | 청구범위 10 | 배경기술 6 | 발명을실시하기위한구체적인내용 122 | \n",
      "patent 1020177037558 's chunk sizes\n",
      "요약 1 | 청구범위 10 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 14 | 발명을실시하기위한구체적인내용 160 | \n",
      "patent 1020177037778 's chunk sizes\n",
      "요약 1 | 청구범위 9 | 기술분야 1 | 배경기술 4 | 발명을실시하기위한구체적인내용 147 | \n",
      "patent 1020180025991 's chunk sizes\n",
      "요약 1 | 청구범위 5 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 5 | 발명의효과 1 | 발명을실시하기위한구체적인내용 21 | \n",
      "patent 1020180087613 's chunk sizes\n",
      "요약 1 | 청구범위 2 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 4 | \n",
      "patent 1020180098000 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 2 | 발명의효과 1 | 발명을실시하기위한구체적인내용 21 | \n",
      "patent 1020180117511 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 6 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 3 | 발명을실시하기위한구체적인내용 18 | \n",
      "patent 1020180141287 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 2 | 발명을실시하기위한구체적인내용 27 | \n",
      "patent 1020187000619 's chunk sizes\n",
      "요약 1 | 청구범위 7 | 기술분야 1 | 배경기술 4 | 발명을실시하기위한구체적인내용 24 | \n",
      "patent 1020187001525 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 6 | 발명을실시하기위한구체적인내용 12 | \n",
      "patent 1020187016970 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 1 | 발명을실시하기위한구체적인내용 19 | \n",
      "patent 1020187023043 's chunk sizes\n",
      "요약 1 | 청구범위 24 | 배경기술 6 | 발명을실시하기위한구체적인내용 122 | \n",
      "patent 1020190004681 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 4 | 해결하려는과제 1 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 29 | \n",
      "patent 1020197004196 's chunk sizes\n",
      "요약 1 | 청구범위 13 | 기술분야 1 | 배경기술 5 | 해결하려는과제 1 | 과제의해결수단 13 | 발명을실시하기위한구체적인내용 63 | \n",
      "patent 1020197008576 's chunk sizes\n",
      "요약 1 | 청구범위 12 | 기술분야 1 | 배경기술 12 | 해결하려는과제 6 | 과제의해결수단 9 | 발명의효과 2 | 발명을실시하기위한구체적인내용 46 | \n",
      "patent 1020197018651 's chunk sizes\n",
      "요약 1 | 청구범위 7 | 기술분야 1 | 배경기술 3 | 발명을실시하기위한구체적인내용 50 | \n",
      "patent 1020197032916 's chunk sizes\n",
      "요약 1 | 청구범위 10 | 기술분야 1 | 배경기술 1 | 과제의해결수단 3 | 발명을실시하기위한구체적인내용 56 | \n",
      "patent 1020197037645 's chunk sizes\n",
      "요약 1 | 청구범위 7 | 기술분야 1 | 배경기술 5 | 발명을실시하기위한구체적인내용 85 | \n",
      "patent 1020200166212 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 1 | 발명을실시하기위한구체적인내용 10 | \n",
      "patent 1020207002060 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 2 | 발명의효과 1 | 발명을실시하기위한구체적인내용 23 | \n",
      "patent 1020207016623 's chunk sizes\n",
      "요약 1 | 청구범위 12 | 기술분야 1 | 배경기술 8 | 발명을실시하기위한구체적인내용 192 | \n",
      "patent 1020207016635 's chunk sizes\n",
      "요약 1 | 청구범위 15 | 기술분야 1 | 배경기술 8 | 발명을실시하기위한구체적인내용 192 | \n",
      "patent 1020207016660 's chunk sizes\n",
      "요약 1 | 청구범위 16 | 기술분야 1 | 배경기술 8 | 발명을실시하기위한구체적인내용 192 | \n",
      "patent 1020207031981 's chunk sizes\n",
      "요약 1 | 청구범위 5 | 기술분야 1 | 배경기술 3 | 과제의해결수단 6 | 발명을실시하기위한구체적인내용 15 | \n",
      "patent 1020210105377 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 2 | 해결하려는과제 2 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 18 | \n",
      "patent 1020210111296 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 1 | 해결하려는과제 2 | 과제의해결수단 1 | 발명의효과 1 | 발명을실시하기위한구체적인내용 11 | \n",
      "patent 1020210160525 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 3 | 발명의효과 1 | 발명을실시하기위한구체적인내용 14 | \n",
      "patent 1020217003575 's chunk sizes\n",
      "요약 1 | 청구범위 39 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 2 | 발명을실시하기위한구체적인내용 147 | \n",
      "patent 1020217003579 's chunk sizes\n",
      "요약 1 | 청구범위 11 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 2 | 발명을실시하기위한구체적인내용 147 | \n",
      "patent 1020220169561 's chunk sizes\n",
      "요약 1 | 청구범위 8 | 기술분야 1 | 배경기술 2 | 해결하려는과제 2 | 과제의해결수단 3 | 발명의효과 1 | 발명을실시하기위한구체적인내용 200 | \n",
      "patent 1020227011870 's chunk sizes\n",
      "요약 1 | 청구범위 9 | 기술분야 1 | 배경기술 1 | 해결하려는과제 1 | 과제의해결수단 14 | 발명을실시하기위한구체적인내용 160 | \n",
      "patent 1020227013328 's chunk sizes\n",
      "요약 1 | 청구범위 8 | 기술분야 1 | 배경기술 5 | 해결하려는과제 1 | 과제의해결수단 13 | 발명을실시하기위한구체적인내용 63 | \n",
      "patent 1020227022151 's chunk sizes\n",
      "요약 1 | 청구범위 38 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 2 | 발명을실시하기위한구체적인내용 147 | \n",
      "patent 1020227032748 's chunk sizes\n",
      "요약 1 | 청구범위 7 | 기술분야 1 | 배경기술 4 | 해결하려는과제 1 | 과제의해결수단 2 | 발명을실시하기위한구체적인내용 15 | \n",
      "patent 1020227044393 's chunk sizes\n",
      "요약 1 | 청구범위 7 | 기술분야 1 | 배경기술 5 | 해결하려는과제 1 | 과제의해결수단 13 | 발명을실시하기위한구체적인내용 63 | \n",
      "patent 1020237014986 's chunk sizes\n",
      "요약 1 | 청구범위 7 | 기술분야 1 | 배경기술 5 | 해결하려는과제 1 | 과제의해결수단 13 | 발명을실시하기위한구체적인내용 63 | \n",
      "patent 2020170000715 's chunk sizes\n",
      "요약 1 | 청구범위 3 | 기술분야 1 | 배경기술 4 | 해결하려는과제 1 | 과제의해결수단 2 | \n",
      "patent 2020180004413 's chunk sizes\n",
      "요약 1 | 청구범위 4 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 4 | \n",
      "patent 2020190003225 's chunk sizes\n",
      "요약 2 | 청구범위 2 | 기술분야 1 | 배경기술 2 | 해결하려는과제 1 | 과제의해결수단 3 | \n"
     ]
    }
   ],
   "source": [
    "patent_chunk_dicts=[]\n",
    "\n",
    "for i, row in sample_data.iterrows():\n",
    "    patent_dict = dict( \n",
    "        # 특허 번호 따기\n",
    "        application_number = str(row.id), # 출원 번호\n",
    "        publication_number = '', # 공개 번호\n",
    "        patent_number = '', # 등록 번호\n",
    "        chunks = [],\n",
    "        # chunks_wo_drawing_and_numbers_desc = []\n",
    "    )\n",
    "    print(f\"patent {row.id} 's chunk sizes\")\n",
    "    \n",
    "    # text column들을 돌면서, chunking 하기\n",
    "    chunks = []\n",
    "    drawing_nums_list = []\n",
    "    refs_list = []\n",
    "    # chunks_wo_drawing_desc = [] # 도면의 간단한 설명, 부호의 설명 제외.. false positive 가 생기지는 않을까?\n",
    "    for col in text_columns:\n",
    "        if (col in ['도면의간단한설명', '부호의설명']) or (str(row[col]) == 'nan'):\n",
    "            continue\n",
    "        curr_section_chunks = text_splitter.create_documents([str(row[col])], [{\"application_number\": str(row.id)}])\n",
    "        chunks.extend(curr_section_chunks)\n",
    "        \n",
    "        # chunks_wo_drawing_desc.extend(curr_section_chunks)\n",
    "        print(col, len(curr_section_chunks), end=' | ')\n",
    "        \n",
    "        # chunk 별로 reference 발생한 부호 찾기\n",
    "        for chnk in curr_section_chunks:\n",
    "            refs = extract_ref_from_text(chnk)\n",
    "            refs_list.append(refs)\n",
    "            \n",
    "            #  부호가 있었으면 drawing number 로 한번 또 치환하기\n",
    "            if len(refs) > 0: # if not empty, convert found references to drawing numbers\n",
    "                drawing_nums = convert_refs_to_drawing_num(refs, num2drawing_dicts[str(row.id)]['num2drawing'])\n",
    "            else:\n",
    "                drawing_nums = []\n",
    "            drawing_nums_list.append(drawing_nums)\n",
    "                \n",
    "        \n",
    "    # patent_dict['chunks'] = list(zip(chunks, zip(refs_list, drawing_nums_list)))\n",
    "    patent_dict['chunks'] = chunks\n",
    "    # patent_dict['chunks_wo_drawing_and_numbers_desc'] = chunks_wo_drawing_desc\n",
    "    print()\n",
    "    patent_chunk_dicts.append(patent_dict)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(patent_chunk_dicts, open('data_preprocess/sample_chunk_data.json', 'w'), ensure_ascii = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in select_columns:\n",
    "#     sample_data[f\"{col}_ref\"] = sample_data[col].apply(extract_ref_from_text)\n",
    "\n",
    "# sample_data['도면의간단한설명_dict'] = sample_data['도면의간단한설명'].apply(extract_description_for_image)\n",
    "\n",
    "# sample_data.loc[:,'부호의설명_dict'] = sample_data['부호의설명'].apply(extract_description_for_code)\n",
    "\n",
    "# for col in select_columns:\n",
    "#     sample_data[f\"{col}_ref_drawing\"] = sample_data.apply(convert_ref_to_drawing_num, args=(col,image_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR\n",
    "\n",
    "- Tesseract : 잘 못함\n",
    "- 다른 오픈소스 : pyocr -> tesseract랑 똑같음 / calamari-ocr -> tensorflow 설치해야 되고 등등 maintain이 잘 안되는 패키지 인듯\n",
    "- GCP vision api : 일단 ui 에서 테스트 해보고 copy json output 버튼 눌러가지고 json output 복사해와서 json output에서 텍스트만 파싱하는 것만 짬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "## tesseract를 먼저 다운받고, 다운받은 경로를 넣어주어야 함.\n",
    "## You need to first download tesseract & insert the path to the exe file below.\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Cellar/tesseract/5.3.3/bin/tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_preprocess/image/pdf_1020120156759/p8-6.png\n",
      "\n",
      "data_preprocess/image/pdf_1020120156759/p7-31.png\n",
      "A256\n",
      "ART\n",
      "129\n",
      "A120\n",
      "A158\n",
      "123,\n",
      "121\n",
      "\n",
      "133\n",
      "\n",
      "A35\n",
      "437\n",
      "\n",
      "10 130110 145: 147\n",
      "140- 143\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020120156759/p7-30.png\n",
      "110 5 110\n",
      "\n",
      "1 ~_-f\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020120156759/p0-6.png\n",
      "\n",
      "data_preprocess/image/pdf_1020120156759/p9-39.png\n",
      "200\n",
      "\n",
      "212\n",
      "214a\n",
      "\n",
      "222 224a 226 228\n",
      "\n",
      "data_preprocess/image/pdf_1020120156759/p8-35.png\n",
      "200\n",
      "\n",
      "300\n",
      "\n",
      "320\n",
      "310\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020180014052/p14-56.png\n",
      "\n",
      "data_preprocess/image/pdf_1020180014052/p12-6.png\n",
      "\n",
      "data_preprocess/image/pdf_1020180014052/p15-60.png\n",
      "\n",
      "data_preprocess/image/pdf_1020180014052/p0-6.png\n",
      "\n",
      "data_preprocess/image/pdf_1020180014052/p13-52.png\n",
      "\n",
      "data_preprocess/image/pdf_1020180014052/p11-43.png\n",
      "\n",
      "data_preprocess/image/pdf_1020180014052/p11-44.png\n",
      "\n",
      "data_preprocess/image/pdf_1020180014052/p11-45.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p13-66.png\n",
      "1\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "\\\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p13-67.png\n",
      "La\n",
      "\n",
      "4 a, 3 i\n",
      "cs ot “\n",
      "Qo seeeenumaaediaeotdepe, oe r\n",
      "ay, 4 ”\n",
      "4 a aw\n",
      "¥ *\n",
      "’\n",
      "\n",
      "ee,\n",
      "? WU nde eee AER EE EARS eet etme |W PS capeneuettt\n",
      "\n",
      "5\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p13-65.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p9-37.png\n",
      "7)\n",
      "\n",
      "gibinenenes PTRTEPIG TOPPER sr rresi ries od) 4\n",
      "\n",
      "ce |\n",
      "\n",
      "Padaeeny ARR ER GARR EN ESTO APRN ESET\n",
      "\n",
      "SEAAP ET EDT ERA EET AAT ETRE PSR ee,\n",
      "\n",
      ". hia ?\n",
      "eepeaeeeb taba ah psanecken deseenneye pe gy) id\n",
      "\n",
      "uw\n",
      "\n",
      "La\n",
      "MORNE POPU EA UNCRAE TATRA SHHE SURE ME P®\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p8-6.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p9-36.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p10-46.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p10-47.png\n",
      "ESSSSSSeSsy\n",
      "\n",
      "EE\n",
      "\n",
      "3\n",
      "\n",
      "o\n",
      "vi\n",
      "tl =\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p10-45.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p10-44.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p12-58.png\n",
      "1 BEGSESTO RF ERSP ERECT EVER R ARR RT ERR ESE\n",
      "\n",
      "3 Se ERROR Eee\n",
      "\n",
      "s\n",
      "5 CCRCRMORMARARBORARAR SURE RE eeRT eee Ee”\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p0-6.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p12-59.png\n",
      "10\n",
      "\n",
      "PHASE REED SERRE EMER EEN ERE\n",
      "\n",
      "PSPURD ETERS UE RECS HERETO SEMPRE PTET E RE\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p9-38.png\n",
      "FAVA CRAP ECR S PREP ERO ET 6\n",
      "\n",
      "PEP cee 7\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p9-39.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p12-61.png\n",
      "(POPVERer ret iste ee erst Teter rarer,\n",
      "\n",
      "VEC TeRErerrrerr relist Petree ree tare)\n",
      "\n",
      "nurscahepretieasnacrannet®\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p12-60.png\n",
      "1 SRT STRA EAN REAM HAAR ER ATER TREN RAR\n",
      "\n",
      "10 COP SAS TARR RARE\n",
      "\n",
      "s\n",
      "5 PPTTTTTTITITTIT rire ie eT Le\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p11-54.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p11-51.png\n",
      "dw\n",
      "\n",
      "412\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p11-53.png\n",
      "\n",
      "data_preprocess/image/pdf_1020177009557/p11-52.png\n",
      "\n",
      "data_preprocess/image/pdf_1020050097605/p5-47.png\n",
      "50\n",
      "\n",
      "30\n",
      "\n",
      "AQ\n",
      "\n",
      "10\n",
      "\n",
      "data_preprocess/image/pdf_1020050097605/p4-42.png\n",
      "30\n",
      "\n",
      "100\n",
      "\n",
      "AQ\n",
      "\n",
      "10\n",
      "\n",
      "data_preprocess/image/pdf_1020050097605/p4-41.png\n",
      "op)\n",
      "—\n",
      "\n",
      "\n",
      "data_preprocess/image/pdf_1020050097605/p4-40.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text image to string\n",
    "from glob import glob\n",
    "\n",
    "image_paths = glob('data_preprocess/image/*/*.png')\n",
    "\n",
    "for img in image_paths:\n",
    "    print(img)\n",
    "    print(pytesseract.image_to_string(Image.open(img), lang='eng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "100\n",
      "40\n",
      "20\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in json_output['fullTextAnnotation']['pages'][0]['blocks']:\n",
    "    for j in i['paragraphs']:\n",
    "        for k in j['words']:\n",
    "            curr_word = ''\n",
    "            for l in k['symbols']:\n",
    "                curr_word += l['text']\n",
    "            if curr_word.startswith('-'):\n",
    "                curr_word = curr_word[1:]\n",
    "            print(curr_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-30', '100', '40', '20', '-10']\n"
     ]
    }
   ],
   "source": [
    "annotations = json_output['textAnnotations'][0]['description'].split('\\n')\n",
    "print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15', '***************', '17']\n"
     ]
    }
   ],
   "source": [
    "annotations = json_output['textAnnotations'][0]['description'].split('\\n')\n",
    "print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4ds-patent-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
